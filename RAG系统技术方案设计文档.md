# éº’éºŸæ“ä½œç³»ç»Ÿæ‰‹å†ŒRAGæ£€ç´¢ç³»ç»ŸæŠ€æœ¯æ–¹æ¡ˆ

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### ä¸šåŠ¡èƒŒæ™¯

åŸºäº**éº’éºŸæ¡Œé¢æ“ä½œç³»ç»Ÿæ“ä½œæ‰‹å†Œ**(7.7MB PDFæ–‡æ¡£)ï¼Œæ„å»ºæ™ºèƒ½æ–‡æ¡£æ£€ç´¢ç³»ç»Ÿï¼Œå®ç°"ç”¨æˆ·æé—®â†’æ£€ç´¢æœ€ç›¸å…³æ–‡æ¡£ç‰‡æ®µ"çš„æ ¸å¿ƒæµç¨‹ã€‚æ–‡æ¡£åŒ…å«å¤§é‡å›¾è¡¨ã€è¡¨æ ¼å’Œç»“æ„åŒ–å†…å®¹ï¼Œéœ€è¦ä¸“é—¨çš„å¤šæ¨¡æ€å¤„ç†ç­–ç•¥ã€‚

### æ ¸å¿ƒç›®æ ‡

- **æ–‡æ¡£ç†è§£**ï¼šå‡†ç¡®è§£æåŒ…å«å›¾ç‰‡ã€è¡¨æ ¼çš„PDFæ–‡æ¡£
- **è¯­ä¹‰æ£€ç´¢**ï¼šåŸºäºç”¨æˆ·æé—®è¿”å›top-3æœ€ç›¸å…³æ–‡æœ¬ç‰‡æ®µ
- **ç»“æ„ä¿ç•™**ï¼šç»´æŒæ–‡æ¡£åŸæœ‰å±‚çº§ç»“æ„å’Œè¯­ä¹‰å®Œæ•´æ€§
- **ä¸­æ–‡ä¼˜åŒ–**ï¼šé’ˆå¯¹ä¸­æ–‡æ–‡æ¡£ç‰¹ç‚¹è¿›è¡Œä¼˜åŒ–

## ğŸ”§ æŠ€æœ¯é€‰å‹

### æ ¸å¿ƒæŠ€æœ¯æ ˆ

```text
PyMuPDF + pdfplumber (æ–‡æ¡£è§£æ) 
    â†“
Markdownæ ¼å¼è½¬æ¢ (ç»“æ„åŒ–å­˜å‚¨)
    â†“
BGE-large-zh-v1.5 (ä¸­æ–‡å‘é‡åŒ–)
    â†“
Qdrant (å‘é‡æ•°æ®åº“)
    â†“
LangChain (RAGæ¡†æ¶)
```

### æŠ€æœ¯é€‰å‹å¯¹æ¯”

| ç»„ä»¶ç±»å‹ | é€‰æ‹©æ–¹æ¡ˆ | å¤‡é€‰æ–¹æ¡ˆ | é€‰æ‹©ç†ç”± |
|---------|---------|---------|---------|
| **PDFè§£æ** | PyMuPDF + pdfplumber | Unstructured, LayoutParser | å¹³è¡¡æ€§èƒ½ä¸å¤æ‚åº¦ï¼Œä¸­æ–‡æ”¯æŒä¼˜ç§€ |
| **å‘é‡æ¨¡å‹** | BGE-large-zh-v1.5 | OpenAI Embeddings | ä¸“é—¨é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–ï¼Œæœ¬åœ°éƒ¨ç½² |
| **å‘é‡æ•°æ®åº“** | Qdrant | FAISS, ChromaDB | ç°ä»£åŒ–è®¾è®¡ï¼ŒAPIå‹å¥½ï¼Œå†…å­˜æ¨¡å¼ |
| **RAGæ¡†æ¶** | LangChain | è‡ªå®ç° | ç”Ÿæ€å®Œæ•´ï¼Œå¿«é€Ÿå¼€å‘ |

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„å›¾

```mermaid
graph TD
    A[PDFæ–‡æ¡£] --> B[æ–‡æ¡£è§£æå™¨]
    B --> C[Markdownè½¬æ¢]
    B --> D[å›¾ç‰‡æå–]
    B --> E[è¡¨æ ¼æå–]
    
    C --> F[ç»“æ„åŒ–åˆ†ç‰‡å™¨]
    D --> G[å›¾ç‰‡æè¿°ç”Ÿæˆ]
    E --> H[è¡¨æ ¼æ ¼å¼åŒ–]
    
    G --> F
    H --> F
    F --> I[æ–‡æœ¬å‘é‡åŒ–]
    I --> J[Qdrantå‘é‡å­˜å‚¨]
    
    K[ç”¨æˆ·æŸ¥è¯¢] --> L[æŸ¥è¯¢å‘é‡åŒ–]
    L --> M[ç›¸ä¼¼åº¦æ£€ç´¢]
    J --> M
    M --> N[ç»“æœæ’åº]
    N --> O[Top-3ç‰‡æ®µè¿”å›]
```

### æ•°æ®æµè®¾è®¡

```text
# æ•°æ®å¤„ç†æµç¨‹
PDFæ–‡æ¡£ (7.7MB)
â”œâ”€â”€ æ–‡æœ¬æå– â†’ ç»“æ„åŒ–Markdown
â”œâ”€â”€ å›¾ç‰‡æå– â†’ LLMæè¿° â†’ ![å›¾ç‰‡](path) + æè¿°æ–‡æœ¬
â””â”€â”€ è¡¨æ ¼æå– â†’ Markdownè¡¨æ ¼æ ¼å¼

â†“ 
æ™ºèƒ½åˆ†ç‰‡ (æŒ‰å±‚çº§ + RecursiveTextSplitter)
â”œâ”€â”€ Chunk 1: æ–‡æœ¬ + å…ƒæ•°æ®
â”œâ”€â”€ Chunk 2: è¡¨æ ¼ + ä¸Šä¸‹æ–‡
â””â”€â”€ Chunk 3: å›¾ç‰‡æè¿° + å¼•ç”¨

â†“
å‘é‡åŒ– (BGE-large-zh-v1.5, 1024ç»´)
â””â”€â”€ å­˜å‚¨åˆ°Qdrant Collection
```

## ğŸ” æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 1. å¤šæ¨¡æ€æ–‡æ¡£è§£æå™¨

#### 1.1 PDFåˆ°Markdownè½¬æ¢

```python
class MultiModalPDFParser:
    def __init__(self):
        self.text_extractor = PyMuPDF()
        self.table_extractor = pdfplumber  
        self.image_extractor = PyMuPDF()
        
    def parse_to_markdown(self, pdf_path):
        """
        å°†PDFè½¬æ¢ä¸ºç»“æ„åŒ–Markdown
        """
        result = {
            'markdown_content': '',
            'images': [],
            'tables': [],
            'metadata': {}
        }
        
        # 1. æå–æ–‡æœ¬ç»“æ„
        text_blocks = self.extract_structured_text()
        
        # 2. è¯†åˆ«å¹¶æå–è¡¨æ ¼
        tables = self.extract_tables()
        
        # 3. æå–å¹¶æè¿°å›¾ç‰‡
        images = self.extract_and_describe_images()
        
        # 4. åˆå¹¶ä¸ºMarkdownæ ¼å¼
        markdown = self.merge_to_markdown(text_blocks, tables, images)
        
        return result
```

#### 1.2 å›¾ç‰‡å¤„ç†ç­–ç•¥

```python
class ImageProcessor:
    def __init__(self):
        # ä½¿ç”¨å¼€æºå›¾ç‰‡æè¿°æ¨¡å‹
        self.image_captioner = pipeline(
            "image-to-text", 
            model="Salesforce/blip2-opt-2.7b"
        )
    
    def process_image(self, image_data, page_num, image_index):
        """
        å¤„ç†å•å¼ å›¾ç‰‡ï¼šä¿å­˜ + ç”Ÿæˆæè¿°
        """
        # 1. ä¿å­˜å›¾ç‰‡
        image_path = f"images/page_{page_num}_img_{image_index}.png"
        image_data.save(image_path)
        
        # 2. ç”Ÿæˆæè¿°
        description = self.image_captioner(image_data)[0]['generated_text']
        
        # 3. è¿”å›Markdownæ ¼å¼
        return f"![{description}]({image_path})\n\n**å›¾ç‰‡æè¿°**: {description}\n"
```

#### 1.3 è¡¨æ ¼å¤„ç†ç­–ç•¥

```python
class TableProcessor:
    def extract_table_to_markdown(self, table_data, context_before, context_after):
        """
        å°†è¡¨æ ¼è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œä¿ç•™ä¸Šä¸‹æ–‡
        """
        # 1. è½¬æ¢ä¸ºMarkdownè¡¨æ ¼
        markdown_table = self.dataframe_to_markdown(table_data)
        
        # 2. æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        result = f"""
{context_before}

{markdown_table}

{context_after}
        """
        return result.strip()
```

### 2. æ™ºèƒ½åˆ†ç‰‡å™¨

#### 2.1 æ··åˆåˆ†ç‰‡ç­–ç•¥

```python
class HybridChunker:
    def __init__(self):
        self.max_chunk_size = 500  # ä¸­æ–‡å­—ç¬¦
        self.overlap = 50
        self.preserve_elements = True
        
    def chunk_markdown(self, markdown_content):
        """
        æ··åˆåˆ†ç‰‡ç­–ç•¥ï¼šå±‚çº§ + é€’å½’
        """
        chunks = []
        
        # 1. æŒ‰æ ‡é¢˜å±‚çº§é¢„åˆ†å‰²
        sections = self.split_by_headers(markdown_content)
        
        for section in sections:
            if self.is_oversized(section):
                # å¤§ç« èŠ‚ï¼šé€’å½’åˆ†å‰²ï¼Œä¿æŒè¡¨æ ¼/å›¾ç‰‡å®Œæ•´
                sub_chunks = self.recursive_split_preserve_elements(section)
                chunks.extend(sub_chunks)
            else:
                # å°ç« èŠ‚ï¼šç›´æ¥ä½œä¸ºä¸€ä¸ªchunk
                chunks.append(self.create_chunk(section))
                
        return chunks
    
    def recursive_split_preserve_elements(self, text):
        """
        é€’å½’åˆ†å‰²ï¼Œä¿æŠ¤è¡¨æ ¼å’Œå›¾ç‰‡ä¸è¢«æˆªæ–­
        """
        # è¯†åˆ«ä¿æŠ¤åŒºåŸŸ
        protected_ranges = self.find_protected_elements(text)
        
        # åœ¨å®‰å…¨ä½ç½®åˆ†å‰²
        return self.safe_split(text, protected_ranges)
```

#### 2.2 å…ƒæ•°æ®è®¾è®¡

```python
class ChunkMetadata:
    """
    ä¸°å¯Œçš„chunkå…ƒæ•°æ®è®¾è®¡
    """
    def create_metadata(self, chunk_content, section_info):
        return {
            "chunk_id": f"section_{section_info.level}_{section_info.index}",
            "section_hierarchy": section_info.hierarchy,  # ["1", "1.2", "1.2.1"]
            "section_title": section_info.title,
            "parent_section": section_info.parent,
            "page_range": [section_info.start_page, section_info.end_page],
            "content_types": self.analyze_content_types(chunk_content),
            "element_counts": {
                "tables": self.count_tables(chunk_content),
                "images": self.count_images(chunk_content),
                "text_length": len(chunk_content)
            },
            "cross_references": self.extract_references(chunk_content),
            "keywords": self.extract_keywords(chunk_content)
        }
```

### 3. å‘é‡æ£€ç´¢å™¨

#### 3.1 Qdranté›†æˆ

```python
class QdrantRetriever:
    def __init__(self):
        self.client = QdrantClient(":memory:")  # å†…å­˜æ¨¡å¼
        self.collection_name = "kylinos_docs"
        
    def setup_collection(self):
        """
        åˆ›å»ºå‘é‡é›†åˆ
        """
        self.client.create_collection(
            collection_name=self.collection_name,
            vectors_config=models.VectorParams(
                size=1024,  # BGEæ¨¡å‹ç»´åº¦
                distance=models.Distance.COSINE
            )
        )
    
    def add_documents(self, chunks):
        """
        æ‰¹é‡æ·»åŠ æ–‡æ¡£å—
        """
        points = []
        for i, chunk in enumerate(chunks):
            points.append(models.PointStruct(
                id=i,
                vector=chunk.embedding,
                payload={
                    "content": chunk.content,
                    "metadata": chunk.metadata
                }
            ))
        
        self.client.upsert(
            collection_name=self.collection_name,
            points=points
        )
    
    def search(self, query_embedding, top_k=3):
        """
        ç›¸ä¼¼åº¦æ£€ç´¢
        """
        search_result = self.client.search(
            collection_name=self.collection_name,
            query_vector=query_embedding,
            limit=top_k,
            with_payload=True
        )
        
        return [
            {
                "content": hit.payload["content"],
                "metadata": hit.payload["metadata"], 
                "score": hit.score
            }
            for hit in search_result
        ]
```

#### 3.2 æ··åˆæ£€ç´¢ç­–ç•¥

```python
class HybridSearchEngine:
    def __init__(self):
        self.vector_retriever = QdrantRetriever()
        self.keyword_retriever = BM25Retriever()  # å…³é”®è¯æ£€ç´¢
        
    def search(self, query, top_k=3):
        """
        å¤šç­–ç•¥èåˆæ£€ç´¢
        """
        # 1. å‘é‡æ£€ç´¢
        vector_results = self.vector_retriever.search(query, top_k*2)
        
        # 2. å…³é”®è¯æ£€ç´¢ï¼ˆç‰¹åˆ«é€‚åˆè¡¨æ ¼å†…å®¹ï¼‰
        keyword_results = self.keyword_retriever.search(query, top_k*2)
        
        # 3. ç»“æœèåˆä¸é‡æ’åº
        final_results = self.rank_fusion(vector_results, keyword_results)
        
        return final_results[:top_k]
```

## âš ï¸ é£é™©ä¸æŒ‘æˆ˜

### ä¸»è¦é£é™©

1. **PDFè§£æå‡†ç¡®æ€§**
   - å¤æ‚å¸ƒå±€å¯èƒ½å¯¼è‡´æ–‡æœ¬é¡ºåºé”™ä¹±
   - è¡¨æ ¼è¯†åˆ«å¯èƒ½ä¸å®Œæ•´
   - **ç¼“è§£æ–¹æ¡ˆ**ï¼šå®ç°è´¨é‡æ£€æŸ¥æœºåˆ¶

2. **åˆ†ç‰‡å¤§å°ä¸å‡åŒ€**
   - åŒ…å«å¤§è¡¨æ ¼çš„chunkå¯èƒ½è¿‡å¤§
   - **ç¼“è§£æ–¹æ¡ˆ**ï¼šå®ç°åŠ¨æ€å¤§å°è°ƒæ•´

3. **è·¨ç« èŠ‚è¯­ä¹‰å…³è”ä¸¢å¤±**
   - ç›¸å…³å†…å®¹å¯èƒ½è¢«åˆ†å‰²åˆ°ä¸åŒchunk
   - **ç¼“è§£æ–¹æ¡ˆ**ï¼šå¢åŠ cross-referenceå…ƒæ•°æ®

4. **ä¸­æ–‡å‘é‡åŒ–æ•ˆæœ**
   - ä¸“ä¸šæœ¯è¯­å‘é‡åŒ–å¯èƒ½ä¸å‡†ç¡®
   - **ç¼“è§£æ–¹æ¡ˆ**ï¼šé¢†åŸŸè¯å…¸é¢„å¤„ç†

### æ€§èƒ½è€ƒè™‘

- **å†…å­˜ä½¿ç”¨**ï¼šBGEæ¨¡å‹çº¦1.3GBï¼ŒQdrantå†…å­˜å­˜å‚¨é€‚ä¸­
- **å¤„ç†é€Ÿåº¦**ï¼š7.7MB PDFé¢„è®¡å¤„ç†æ—¶é—´2-3åˆ†é’Ÿ
- **æ£€ç´¢å»¶è¿Ÿ**ï¼šå•æ¬¡æŸ¥è¯¢é¢„è®¡<100ms

## ğŸ“ é¡¹ç›®ç»“æ„

```text
rag_kylinos/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py          # PDFè§£æå™¨
â”‚   â”‚   â”œâ”€â”€ image_processor.py     # å›¾ç‰‡å¤„ç†å™¨
â”‚   â”‚   â””â”€â”€ table_processor.py     # è¡¨æ ¼å¤„ç†å™¨
â”‚   â”œâ”€â”€ chunkers/
â”‚   â”‚   â”œâ”€â”€ hybrid_chunker.py      # æ··åˆåˆ†ç‰‡å™¨
â”‚   â”‚   â””â”€â”€ metadata_generator.py  # å…ƒæ•°æ®ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ retrievers/
â”‚   â”‚   â”œâ”€â”€ qdrant_retriever.py    # Qdrantæ£€ç´¢å™¨
â”‚   â”‚   â””â”€â”€ hybrid_search.py       # æ··åˆæ£€ç´¢å¼•æ“
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ bge_embedder.py        # BGEå‘é‡åŒ–å™¨
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ quality_checker.py     # è´¨é‡æ£€æŸ¥
â”‚       â””â”€â”€ markdown_utils.py      # Markdownå·¥å…·
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ kylinos_handle_book.pdf
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ markdown/              # è½¬æ¢åçš„markdownæ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ images/                # æå–çš„å›¾ç‰‡
â”‚   â”‚   â””â”€â”€ chunks/                # åˆ†ç‰‡ç»“æœ
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ main.py                        # ä¸»ç¨‹åºå…¥å£
```

## ğŸ’¡ åˆ›æ–°ç‚¹æ€»ç»“

1. **ç»“æ„åŒ–ä¸­é—´æ ¼å¼**ï¼šä½¿ç”¨Markdownä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå¹³è¡¡å¯è¯»æ€§å’Œç»“æ„åŒ–
2. **å¤šæ¨¡æ€èåˆå¤„ç†**ï¼šå›¾ç‰‡æè¿°+è¡¨æ ¼ç»“æ„åŒ–+æ–‡æœ¬çš„ç»Ÿä¸€å¤„ç†
3. **æ™ºèƒ½åˆ†ç‰‡ç­–ç•¥**ï¼šå±‚çº§é¢„åˆ†å‰²+é€’å½’ç»†åˆ†+å…ƒç´ ä¿æŠ¤çš„æ··åˆç­–ç•¥
4. **ä¸°å¯Œå…ƒæ•°æ®è®¾è®¡**ï¼šæ”¯æŒå¤šç»´åº¦æ£€ç´¢å’Œç»“æœæ’åº
5. **ç°ä»£åŒ–æŠ€æœ¯æ ˆ**ï¼šQdrantå‘é‡æ•°æ®åº“+BGEä¸­æ–‡æ¨¡å‹çš„ç»„åˆ

## ğŸ”š æ€»ç»“

æœ¬æ–¹æ¡ˆé‡‡ç”¨ç°ä»£åŒ–RAGæŠ€æœ¯æ ˆï¼Œé’ˆå¯¹åŒ…å«ä¸°å¯Œå›¾è¡¨çš„ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£ç‰¹ç‚¹ï¼Œè®¾è®¡äº†å®Œæ•´çš„å¤šæ¨¡æ€å¤„ç†æµç¨‹ã€‚é€šè¿‡Markdownä¸­é—´æ ¼å¼ã€æ™ºèƒ½åˆ†ç‰‡ç­–ç•¥å’Œæ··åˆæ£€ç´¢å¼•æ“ï¼Œå®ç°é«˜è´¨é‡çš„æ–‡æ¡£æ£€ç´¢ç³»ç»Ÿã€‚

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**

- âœ… **ä¸­æ–‡ä¼˜åŒ–**ï¼šä¸“é—¨é’ˆå¯¹ä¸­æ–‡æ–‡æ¡£å’ŒæŸ¥è¯¢ä¼˜åŒ–
- âœ… **ç»“æ„ä¿ç•™**ï¼šç»´æŒæ–‡æ¡£å±‚çº§ç»“æ„å’Œå…ƒç´ å®Œæ•´æ€§  
- âœ… **å¤šæ¨¡æ€æ”¯æŒ**ï¼šç»Ÿä¸€å¤„ç†æ–‡æœ¬ã€å›¾ç‰‡ã€è¡¨æ ¼
- âœ… **ç°ä»£åŒ–æ¶æ„**ï¼šä½¿ç”¨æœ€æ–°çš„å‘é‡æ•°æ®åº“å’Œembeddingæ¨¡å‹
- âœ… **å¯æ‰©å±•è®¾è®¡**ï¼šä¾¿äºåç»­åŠŸèƒ½æ‰©å±•å’Œæ€§èƒ½ä¼˜åŒ–

è¯¥æ–¹æ¡ˆåœ¨é¢è¯•åœºæ™¯ä¸­å±•ç°äº†å¯¹RAGæŠ€æœ¯çš„æ·±å…¥ç†è§£ï¼ŒåŒæ—¶ä¿è¯äº†å®ç°çš„å¯è¡Œæ€§å’Œæ•ˆæœçš„å¯éªŒè¯æ€§ã€‚
