# éº’éºŸæ“ä½œç³»ç»Ÿæ‰‹å†ŒRAGæ£€ç´¢ç³»ç»ŸæŠ€æœ¯æ–¹æ¡ˆ

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### ä¸šåŠ¡èƒŒæ™¯

åŸºäº**éº’éºŸæ¡Œé¢æ“ä½œç³»ç»Ÿæ“ä½œæ‰‹å†Œ**(7.7MB PDFæ–‡æ¡£)ï¼Œæ„å»ºæ™ºèƒ½æ–‡æ¡£æ£€ç´¢ç³»ç»Ÿï¼Œå®ç°"ç”¨æˆ·æé—®â†’æ£€ç´¢æœ€ç›¸å…³æ–‡æ¡£ç‰‡æ®µ"çš„æ ¸å¿ƒæµç¨‹ã€‚æ–‡æ¡£åŒ…å«å¤§é‡å›¾è¡¨ã€è¡¨æ ¼å’Œç»“æ„åŒ–å†…å®¹ï¼Œéœ€è¦ä¸“é—¨çš„å¤šæ¨¡æ€å¤„ç†ç­–ç•¥ã€‚

### æ ¸å¿ƒç›®æ ‡

- **æ–‡æ¡£ç†è§£**ï¼šå‡†ç¡®è§£æåŒ…å«å›¾ç‰‡ã€è¡¨æ ¼çš„PDFæ–‡æ¡£
- **è¯­ä¹‰æ£€ç´¢**ï¼šåŸºäºç”¨æˆ·æé—®è¿”å›top-3æœ€ç›¸å…³æ–‡æœ¬ç‰‡æ®µ
- **ç»“æ„ä¿ç•™**ï¼šç»´æŒæ–‡æ¡£åŸæœ‰å±‚çº§ç»“æ„å’Œè¯­ä¹‰å®Œæ•´æ€§
- **ä¸­æ–‡ä¼˜åŒ–**ï¼šé’ˆå¯¹ä¸­æ–‡æ–‡æ¡£ç‰¹ç‚¹è¿›è¡Œä¼˜åŒ–

## ğŸ”§ æŠ€æœ¯é€‰å‹

### æ ¸å¿ƒæŠ€æœ¯æ ˆ

```text
PyMuPDF + pdfplumber (æ–‡æ¡£è§£æ) 
    â†“
Markdownæ ¼å¼è½¬æ¢ (ç»“æ„åŒ–å­˜å‚¨)
    â†“
BGE-large-zh-v1.5 (ä¸­æ–‡å‘é‡åŒ–)
    â†“
Qdrant (å‘é‡æ•°æ®åº“)
    â†“
LangChain (RAGæ¡†æ¶)
```

### æŠ€æœ¯é€‰å‹å¯¹æ¯”

| ç»„ä»¶ç±»å‹ | é€‰æ‹©æ–¹æ¡ˆ | å¤‡é€‰æ–¹æ¡ˆ | é€‰æ‹©ç†ç”± |
|---------|---------|---------|---------|
| **PDFè§£æ** | PyMuPDF + pdfplumber | Unstructured, LayoutParser | å¹³è¡¡æ€§èƒ½ä¸å¤æ‚åº¦ï¼Œä¸­æ–‡æ”¯æŒä¼˜ç§€ |
| **å‘é‡æ¨¡å‹** | BGE-large-zh-v1.5 | OpenAI Embeddings | ä¸“é—¨é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–ï¼Œæœ¬åœ°éƒ¨ç½² |
| **å‘é‡æ•°æ®åº“** | Qdrant | FAISS, ChromaDB | ç°ä»£åŒ–è®¾è®¡ï¼ŒAPIå‹å¥½ï¼Œå†…å­˜æ¨¡å¼ |
| **RAGæ¡†æ¶** | LangChain | è‡ªå®ç° | ç”Ÿæ€å®Œæ•´ï¼Œå¿«é€Ÿå¼€å‘ |

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„å›¾

```mermaid
graph TD
    A[PDFæ–‡æ¡£] --> B[æ–‡æ¡£è§£æå™¨]
    B --> C[Markdownè½¬æ¢]
    B --> D[å›¾ç‰‡æå–]
    B --> E[è¡¨æ ¼æå–]
    
    C --> F[ç»“æ„åŒ–åˆ†ç‰‡å™¨]
    D --> G[å›¾ç‰‡æè¿°ç”Ÿæˆ]
    E --> H[è¡¨æ ¼æ ¼å¼åŒ–]
    
    G --> F
    H --> F
    F --> I[æ–‡æœ¬å‘é‡åŒ–]
    I --> J[Qdrantå‘é‡å­˜å‚¨]
    
    K[ç”¨æˆ·æŸ¥è¯¢] --> L[æŸ¥è¯¢å‘é‡åŒ–]
    L --> M[ç›¸ä¼¼åº¦æ£€ç´¢]
    J --> M
    M --> N[ç»“æœæ’åº]
    N --> O[Top-3ç‰‡æ®µè¿”å›]
```

### æ•°æ®æµè®¾è®¡

```text
# æ•°æ®å¤„ç†æµç¨‹
PDFæ–‡æ¡£ (7.7MB)
â”œâ”€â”€ æ–‡æœ¬æå– â†’ ç»“æ„åŒ–Markdown
â”œâ”€â”€ å›¾ç‰‡æå– â†’ LLMæè¿° â†’ ![å›¾ç‰‡](path) + æè¿°æ–‡æœ¬
â””â”€â”€ è¡¨æ ¼æå– â†’ Markdownè¡¨æ ¼æ ¼å¼

â†“ 
æ™ºèƒ½åˆ†ç‰‡ (æŒ‰å±‚çº§ + RecursiveTextSplitter)
â”œâ”€â”€ Chunk 1: æ–‡æœ¬ + å…ƒæ•°æ®
â”œâ”€â”€ Chunk 2: è¡¨æ ¼ + ä¸Šä¸‹æ–‡
â””â”€â”€ Chunk 3: å›¾ç‰‡æè¿° + å¼•ç”¨

â†“
å‘é‡åŒ– (BGE-large-zh-v1.5, 1024ç»´)
â””â”€â”€ å­˜å‚¨åˆ°Qdrant Collection
```

## ğŸ” æ ¸å¿ƒç»„ä»¶è®¾è®¡


### ğŸ”§ æ ¸å¿ƒç»„ä»¶ï¼šRAGSystemä¸»æ§åˆ¶å™¨

`rag_system.py`æ˜¯æ•´ä¸ªç³»ç»Ÿçš„æ ¸å¿ƒæ§åˆ¶å™¨ï¼Œå°è£…äº†å®Œæ•´çš„RAGæµç¨‹ï¼š

```pseudocode
class RAGSystem:
    """
    RAG System Main Controller
    Encapsulates document processing and query workflow
    """
    
    function __init__(config):
        # Load configuration and initialize components
        load_config(config)
        init_components()
        setup_system_state()
    
    function process_document(pdf_path):
        """
        Complete document processing pipeline:
        Parse -> Chunk -> Vectorize -> Store
        """
        # 1. File validation
        validate_file(pdf_path)
        
        # 2. PDF parsing
        parsed_doc = parser.parse(pdf_path)
        
        # 3. Document chunking
        chunks = chunker.chunk(parsed_doc)
        
        # 4. Vectorization
        embeddings = embedder.embed([chunk.content for chunk in chunks])
        for chunk, embedding in zip(chunks, embeddings):
            chunk.embedding = embedding
        
        # 5. Store to vector database
        retriever.add_documents(chunks)
        
        # 6. Update system state
        update_system_state(chunks, pdf_path)
        
        return processing_statistics
    
    function query(question, top_k=3):
        """
        Query relevant document chunks
        """
        # 1. State validation
        validate_system_ready()
        
        # 2. Query vectorization
        query_embedding = embedder.embed([question])[0]
        
        # 3. Vector retrieval
        results = retriever.search(query_embedding, top_k)
        
        # 4. Post-processing
        filtered_results = post_process_results(results)
        
        return filtered_results
    
    # System management functions
    function get_system_info()
    function clear_database()
    function update_config(new_config)
```

#### ä¸»è¦åŠŸèƒ½æ¨¡å—

1. **ç»„ä»¶ç®¡ç†**
   - è‡ªåŠ¨åˆå§‹åŒ–æ‰€æœ‰å­ç»„ä»¶ï¼ˆè§£æå™¨ã€åˆ†ç‰‡å™¨ã€å‘é‡åŒ–å™¨ã€æ£€ç´¢å™¨ï¼‰
   - é…ç½®éªŒè¯å’Œç»„ä»¶çŠ¶æ€ç®¡ç†
   - æ”¯æŒåŠ¨æ€é…ç½®æ›´æ–°

2. **æ–‡æ¡£å¤„ç†æµç¨‹**
   - æ–‡ä»¶éªŒè¯å’Œé”™è¯¯å¤„ç†
   - å®Œæ•´çš„å¤„ç†ç®¡é“ï¼šè§£æâ†’åˆ†ç‰‡â†’å‘é‡åŒ–â†’å­˜å‚¨
   - å¤„ç†ç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§

3. **æŸ¥è¯¢æ¥å£**
   - çŠ¶æ€éªŒè¯å’Œå‚æ•°æ ¡éªŒ
   - æŸ¥è¯¢å‘é‡åŒ–å’Œç›¸ä¼¼åº¦æ£€ç´¢
   - ç»“æœè¿‡æ»¤å’Œåå¤„ç†

4. **ç³»ç»ŸçŠ¶æ€ç®¡ç†**
   - æ–‡æ¡£å¤„ç†çŠ¶æ€è·Ÿè¸ª
   - ç³»ç»Ÿä¿¡æ¯è·å–
   - æ•°æ®åº“æ¸…ç†å’Œé‡ç½®

### 1. å¤šæ¨¡æ€æ–‡æ¡£è§£æå™¨

#### 1.1 PDFåˆ°Markdownè½¬æ¢

```pseudocode
class MultiModalPDFParser:
    initialize():
        text_extractor = PyMuPDF_library
        table_extractor = pdfplumber_library  
        image_extractor = PyMuPDF_library
        
    function parse_to_markdown(pdf_path):
        """
        Convert PDF to structured Markdown
        """
        result = {
            'markdown_content': '',
            'images': [],
            'tables': [],
            'metadata': {}
        }
        
        # 1. Extract text structure
        text_blocks = extract_structured_text()
        
        # 2. Identify and extract tables
        tables = extract_tables()
        
        # 3. Extract and describe images
        images = extract_and_describe_images()
        
        # 4. Merge to Markdown format
        markdown = merge_to_markdown(text_blocks, tables, images)
        
        return result
```

#### 1.2 å›¾ç‰‡å¤„ç†ç­–ç•¥

```pseudocode
class ImageProcessor:
    initialize():
        # Use open-source image captioning model
        image_captioner = image_description_AI_model("Salesforce/blip2-opt-2.7b")
    
    function process_image(image_data, page_num, image_index):
        """
        Process single image: save + generate description
        """
        # 1. Save image
        image_path = f"images/page_{page_num}_img_{image_index}.png"
        image_data.save(image_path)
        
        # 2. Generate description
        description = image_captioner.generate_description(image_data)
        
        # 3. Return Markdown format
        return f"![{description}]({image_path})\n\n**Image Description**: {description}\n"
```

#### 1.3 è¡¨æ ¼å¤„ç†ç­–ç•¥

```pseudocode
class TableProcessor:
    function extract_table_to_markdown(table_data, context_before, context_after):
        """
        Convert table to Markdown format, preserve context
        """
        # 1. Convert to Markdown table
        markdown_table = convert_to_markdown_table(table_data)
        
        # 2. Add context information
        result = f"""
{context_before}

{markdown_table}

{context_after}
        """
        return result.strip()
```

### 2. æ™ºèƒ½åˆ†ç‰‡å™¨

#### 2.1 æ··åˆåˆ†ç‰‡ç­–ç•¥

```pseudocode
class HybridChunker:
    initialize():
        max_chunk_size = 500  # Chinese characters
        overlap_size = 50
        preserve_elements = True
        
    function chunk_markdown(markdown_content):
        """
        Hybrid chunking strategy: hierarchical + recursive
        """
        chunks = []
        
        # 1. Pre-split by heading levels
        sections = split_by_headers(markdown_content)
        
        for section in sections:
            if is_oversized(section):
                # Large sections: recursive split, keep tables/images intact
                sub_chunks = recursive_split_preserve_elements(section)
                chunks.extend(sub_chunks)
            else:
                # Small sections: directly as one chunk
                chunks.append(create_chunk(section))
                
        return chunks
    
    function recursive_split_preserve_elements(text):
        """
        Recursive split, protect tables and images from truncation
        """
        # Identify protected areas
        protected_ranges = find_protected_elements(text)
        
        # Split at safe positions
        return safe_split(text, protected_ranges)
```

#### 2.2 å…ƒæ•°æ®è®¾è®¡

```pseudocode
class ChunkMetadata:
    """
    Rich chunk metadata design
    """
    function create_metadata(chunk_content, section_info):
        return {
            "chunk_id": f"section_{section_info.level}_{section_info.index}",
            "section_hierarchy": section_info.hierarchy,  # ["1", "1.2", "1.2.1"]
            "section_title": section_info.title,
            "parent_section": section_info.parent,
            "page_range": [section_info.start_page, section_info.end_page],
            "content_types": analyze_content_types(chunk_content),
            "element_counts": {
                "tables": count_tables(chunk_content),
                "images": count_images(chunk_content),
                "text_length": len(chunk_content)
            },
            "cross_references": extract_references(chunk_content),
            "keywords": extract_keywords(chunk_content)
        }
```

### 3. å‘é‡æ£€ç´¢å™¨

#### 3.1 Qdranté›†æˆ

```pseudocode
class QdrantRetriever:
    initialize():
        client = QdrantClient(":memory:")  # Memory mode
        collection_name = "kylinos_docs"
        
    function setup_collection():
        """
        Create vector collection
        """
        client.create_collection(
            collection_name=collection_name,
            vectors_config={
                size=1024,  # BGE model dimension
                distance=cosine_distance
            }
        )
    
    function add_documents(chunks):
        """
        Batch add document chunks
        """
        points = []
        for index, chunk in enumerate(chunks):
            points.append({
                id=index,
                vector=chunk.embedding,
                payload={
                    "content": chunk.content,
                    "metadata": chunk.metadata
                }
            })
        
        client.upsert(
            collection_name=collection_name,
            points=points
        )
    
    function search(query_vector, top_k=3):
        """
        Similarity retrieval
        """
        search_result = client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            limit=top_k,
            with_payload=True
        )
        
        return [
            {
                "content": hit.payload["content"],
                "metadata": hit.payload["metadata"], 
                "score": hit.score
            }
            for hit in search_result
        ]
```

#### 3.2 æ··åˆæ£€ç´¢ç­–ç•¥

```pseudocode
class HybridSearchEngine:
    initialize():
        vector_retriever = QdrantRetriever()
        keyword_retriever = BM25Retriever()  # Keyword retrieval
        
    function search(query, top_k=3):
        """
        Multi-strategy fusion retrieval
        """
        # 1. Vector retrieval
        vector_results = vector_retriever.search(query, top_k*2)
        
        # 2. Keyword retrieval (especially suitable for table content)
        keyword_results = keyword_retriever.search(query, top_k*2)
        
        # 3. Result fusion and reranking
        final_results = rank_fusion(vector_results, keyword_results)
        
        return final_results[:top_k]
```

## âš ï¸ é£é™©ä¸æŒ‘æˆ˜

### ä¸»è¦é£é™©

1. **PDFè§£æå‡†ç¡®æ€§**
   - å¤æ‚å¸ƒå±€å¯èƒ½å¯¼è‡´æ–‡æœ¬é¡ºåºé”™ä¹±
   - è¡¨æ ¼è¯†åˆ«å¯èƒ½ä¸å®Œæ•´
   - **ç¼“è§£æ–¹æ¡ˆ**ï¼šå®ç°è´¨é‡æ£€æŸ¥æœºåˆ¶

2. **åˆ†ç‰‡å¤§å°ä¸å‡åŒ€**
   - åŒ…å«å¤§è¡¨æ ¼çš„chunkå¯èƒ½è¿‡å¤§
   - **ç¼“è§£æ–¹æ¡ˆ**ï¼šå®ç°åŠ¨æ€å¤§å°è°ƒæ•´

3. **è·¨ç« èŠ‚è¯­ä¹‰å…³è”ä¸¢å¤±**
   - ç›¸å…³å†…å®¹å¯èƒ½è¢«åˆ†å‰²åˆ°ä¸åŒchunk
   - **ç¼“è§£æ–¹æ¡ˆ**ï¼šå¢åŠ cross-referenceå…ƒæ•°æ®

4. **ä¸­æ–‡å‘é‡åŒ–æ•ˆæœ**
   - ä¸“ä¸šæœ¯è¯­å‘é‡åŒ–å¯èƒ½ä¸å‡†ç¡®
   - **ç¼“è§£æ–¹æ¡ˆ**ï¼šé¢†åŸŸè¯å…¸é¢„å¤„ç†

### æ€§èƒ½è€ƒè™‘

- **å†…å­˜ä½¿ç”¨**ï¼šBGEæ¨¡å‹çº¦1.3GBï¼ŒQdrantå†…å­˜å­˜å‚¨é€‚ä¸­
- **å¤„ç†é€Ÿåº¦**ï¼š7.7MB PDFé¢„è®¡å¤„ç†æ—¶é—´2-3åˆ†é’Ÿ
- **æ£€ç´¢å»¶è¿Ÿ**ï¼šå•æ¬¡æŸ¥è¯¢é¢„è®¡<100ms

## ğŸ“ é¡¹ç›®ç»“æ„

```text
rag_kylinos/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ rag_system.py              # ğŸ”§ RAGç³»ç»Ÿä¸»æ§åˆ¶å™¨
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py          # PDFè§£æå™¨
â”‚   â”‚   â”œâ”€â”€ image_processor.py     # å›¾ç‰‡å¤„ç†å™¨
â”‚   â”‚   â””â”€â”€ table_processor.py     # è¡¨æ ¼å¤„ç†å™¨
â”‚   â”œâ”€â”€ chunkers/
â”‚   â”‚   â”œâ”€â”€ hybrid_chunker.py      # æ··åˆåˆ†ç‰‡å™¨
â”‚   â”‚   â””â”€â”€ metadata_generator.py  # å…ƒæ•°æ®ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ retrievers/
â”‚   â”‚   â”œâ”€â”€ qdrant_retriever.py    # Qdrantæ£€ç´¢å™¨
â”‚   â”‚   â””â”€â”€ hybrid_search.py       # æ··åˆæ£€ç´¢å¼•æ“
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ bge_embedder.py        # BGEå‘é‡åŒ–å™¨
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ document_models.py     # æ–‡æ¡£æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ search_models.py       # æ£€ç´¢ç»“æœæ¨¡å‹
â”‚   â”‚   â””â”€â”€ config_models.py       # é…ç½®æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ config.py                  # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ exceptions.py              # å¼‚å¸¸å®šä¹‰
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ quality_checker.py     # è´¨é‡æ£€æŸ¥
â”‚       â””â”€â”€ markdown_utils.py      # Markdownå·¥å…·
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ kylinos_handle_book.pdf
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ markdown/              # è½¬æ¢åçš„markdownæ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ images/                # æå–çš„å›¾ç‰‡
â”‚   â”‚   â””â”€â”€ chunks/                # åˆ†ç‰‡ç»“æœ
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ main.py                        # ä¸»ç¨‹åºå…¥å£
```

## ğŸ’¡ åˆ›æ–°ç‚¹æ€»ç»“

1. **ç»“æ„åŒ–ä¸­é—´æ ¼å¼**ï¼šä½¿ç”¨Markdownä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå¹³è¡¡å¯è¯»æ€§å’Œç»“æ„åŒ–
2. **å¤šæ¨¡æ€èåˆå¤„ç†**ï¼šå›¾ç‰‡æè¿°+è¡¨æ ¼ç»“æ„åŒ–+æ–‡æœ¬çš„ç»Ÿä¸€å¤„ç†
3. **æ™ºèƒ½åˆ†ç‰‡ç­–ç•¥**ï¼šå±‚çº§é¢„åˆ†å‰²+é€’å½’ç»†åˆ†+å…ƒç´ ä¿æŠ¤çš„æ··åˆç­–ç•¥
4. **ä¸°å¯Œå…ƒæ•°æ®è®¾è®¡**ï¼šæ”¯æŒå¤šç»´åº¦æ£€ç´¢å’Œç»“æœæ’åº
5. **ç°ä»£åŒ–æŠ€æœ¯æ ˆ**ï¼šQdrantå‘é‡æ•°æ®åº“+BGEä¸­æ–‡æ¨¡å‹çš„ç»„åˆ

## ğŸ”š æ€»ç»“

æœ¬æ–¹æ¡ˆé‡‡ç”¨ç°ä»£åŒ–RAGæŠ€æœ¯æ ˆï¼Œé’ˆå¯¹åŒ…å«ä¸°å¯Œå›¾è¡¨çš„ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£ç‰¹ç‚¹ï¼Œè®¾è®¡äº†å®Œæ•´çš„å¤šæ¨¡æ€å¤„ç†æµç¨‹ã€‚é€šè¿‡Markdownä¸­é—´æ ¼å¼ã€æ™ºèƒ½åˆ†ç‰‡ç­–ç•¥å’Œæ··åˆæ£€ç´¢å¼•æ“ï¼Œå®ç°é«˜è´¨é‡çš„æ–‡æ¡£æ£€ç´¢ç³»ç»Ÿã€‚

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**

- âœ… **ä¸­æ–‡ä¼˜åŒ–**ï¼šä¸“é—¨é’ˆå¯¹ä¸­æ–‡æ–‡æ¡£å’ŒæŸ¥è¯¢ä¼˜åŒ–
- âœ… **ç»“æ„ä¿ç•™**ï¼šç»´æŒæ–‡æ¡£å±‚çº§ç»“æ„å’Œå…ƒç´ å®Œæ•´æ€§  
- âœ… **å¤šæ¨¡æ€æ”¯æŒ**ï¼šç»Ÿä¸€å¤„ç†æ–‡æœ¬ã€å›¾ç‰‡ã€è¡¨æ ¼
- âœ… **ç°ä»£åŒ–æ¶æ„**ï¼šä½¿ç”¨æœ€æ–°çš„å‘é‡æ•°æ®åº“å’Œembeddingæ¨¡å‹
- âœ… **å¯æ‰©å±•è®¾è®¡**ï¼šä¾¿äºåç»­åŠŸèƒ½æ‰©å±•å’Œæ€§èƒ½ä¼˜åŒ–

è¯¥æ–¹æ¡ˆåœ¨é¢è¯•åœºæ™¯ä¸­å±•ç°äº†å¯¹RAGæŠ€æœ¯çš„æ·±å…¥ç†è§£ï¼ŒåŒæ—¶ä¿è¯äº†å®ç°çš„å¯è¡Œæ€§å’Œæ•ˆæœçš„å¯éªŒè¯æ€§ã€‚

## ğŸ“Š é¡¹ç›®å®ç°çŠ¶æ€

### å·²å®ç°åŠŸèƒ½

- [x] RAGç³»ç»Ÿä¸»æ§åˆ¶å™¨
- [x] ç®€å•PDFæ–‡æœ¬è§£æå™¨
- [x] ç®€å•é‡å åˆ†ç‰‡å™¨  
- [x] BGEä¸­æ–‡å‘é‡åŒ–å™¨
- [x] Qdrantå‘é‡å­˜å‚¨
- [x] å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
- [x] CLIå‘½ä»¤è¡Œç•Œé¢
- [x] é…ç½®ç®¡ç†ç³»ç»Ÿ
- [x] æµ‹è¯•å¥—ä»¶

### å¾…å®ç°åŠŸèƒ½

- [ ] å¤šæ¨¡æ€PDFè§£æå™¨ï¼ˆå›¾ç‰‡+è¡¨æ ¼ï¼‰
- [ ] å›¾ç‰‡æè¿°ç”Ÿæˆå™¨
- [ ] æ™ºèƒ½è¡¨æ ¼æå–
- [ ] æ··åˆåˆ†ç‰‡ç­–ç•¥ï¼ˆå±‚çº§+é€’å½’ï¼‰
- [ ] é«˜çº§å…ƒæ•°æ®ç”Ÿæˆ
- [ ] BM25å…³é”®è¯æ£€ç´¢
- [ ] æ··åˆæ£€ç´¢å¼•æ“
- [ ] æŸ¥è¯¢ä¼˜åŒ–
- [ ] Webç”¨æˆ·ç•Œé¢
- [ ] æ€§èƒ½ä¼˜åŒ–
